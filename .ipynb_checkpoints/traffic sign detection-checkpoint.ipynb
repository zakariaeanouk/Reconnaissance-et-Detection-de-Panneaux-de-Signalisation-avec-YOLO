{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3820240e-8b90-401e-bb8d-4f72d87e5312",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Detection model\n",
    "## Preparation du dataset\n",
    "### Changer le chemin des fichiers de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413cd399-1a77-4d77-976c-a5ddc1597b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin du fichier train.txt\n",
    "input_file = \"/Users/zakariaeanouk/Downloads/archive (1)/train.txt\"\n",
    "output_file = \"/Users/zakariaeanouk/Downloads/archive (1)/train_updated.txt\"  # Nouveau fichier avec les chemins corrigés\n",
    "new_image_dir = \"/Users/zakariaeanouk/Downloads/archive (1)/ts/ts/\"  # Nouveau dossier des images\n",
    "\n",
    "# Lire et modifier les chemins\n",
    "with open(input_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "    for line in infile:\n",
    "        # Obtenir le nom du fichier (sans l'ancien chemin)\n",
    "        image_name = line.strip().split(\"/\")[-1]\n",
    "        # Construire le nouveau chemin\n",
    "        new_path = f\"{new_image_dir}{image_name}\"\n",
    "        # Écrire le nouveau chemin dans le fichier de sortie\n",
    "        outfile.write(new_path + \"\\n\")\n",
    "\n",
    "print(f\"Chemins mis à jour et enregistrés dans {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1196aa5-663a-4ae4-aefb-e7a8c9b24cfc",
   "metadata": {},
   "source": [
    "### changer le chemin des fichiers de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e51980-a385-4ee2-bfca-9d27e33ee3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin du fichier train.txt\n",
    "input_file = \"/Users/zakariaeanouk/Downloads/archive (1)/test.txt\"\n",
    "output_file = \"/Users/zakariaeanouk/Downloads/archive (1)/test_updated.txt\"  # Nouveau fichier avec les chemins corrigés\n",
    "new_image_dir = \"/Users/zakariaeanouk/Downloads/archive (1)/ts/ts/\"  # Nouveau dossier des images\n",
    "\n",
    "# Lire et modifier les chemins\n",
    "with open(input_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "    for line in infile:\n",
    "        # Obtenir le nom du fichier (sans l'ancien chemin)\n",
    "        image_name = line.strip().split(\"/\")[-1]\n",
    "        # Construire le nouveau chemin\n",
    "        new_path = f\"{new_image_dir}{image_name}\"\n",
    "        # Écrire le nouveau chemin dans le fichier de sortie\n",
    "        outfile.write(new_path + \"\\n\")\n",
    "\n",
    "print(f\"Chemins mis à jour et enregistrés dans {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46d961-cb67-4fdf-93f9-5b0cd9d3553f",
   "metadata": {},
   "source": [
    "### Déplacer les images de train dans un dossier Train/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8838011-b04f-4c0a-941c-a72d2fb6600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Chemin vers le fichier train.txt\n",
    "train_txt_path = \"/Users/zakariaeanouk/Downloads/archive (1)/train_updated.txt\"\n",
    "\n",
    "# Chemin du dossier où les images seront copiées\n",
    "output_dir = \"/Users/zakariaeanouk/Downloads/archive (1)/Train/images\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Créer le dossier s'il n'existe pas\n",
    "\n",
    "# Lire les chemins des images depuis train.txt\n",
    "with open(train_txt_path, \"r\") as file:\n",
    "    image_paths = file.readlines()\n",
    "\n",
    "# Supprimer les espaces ou caractères inutiles\n",
    "image_paths = [path.strip() for path in image_paths]\n",
    "\n",
    "# Copier les images dans le dossier de sortie\n",
    "for image_path in image_paths:\n",
    "    if os.path.exists(image_path):  # Vérifie que l'image existe\n",
    "        shutil.copy(image_path, output_dir)\n",
    "    else:\n",
    "        print(f\"Image non trouvée : {image_path}\")\n",
    "\n",
    "print(\"Les images ont été copiées dans le dossier 'train/images'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6820718-4402-46df-ab11-b73f58cc7db7",
   "metadata": {},
   "source": [
    "### Déplacer les images de train dans un dossier Test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49314a3c-7a03-421a-86d6-3cc455bcf49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Chemin vers le fichier train.txt\n",
    "train_txt_path = \"/Users/zakariaeanouk/Downloads/archive (1)/test_updated.txt\"\n",
    "\n",
    "# Chemin du dossier où les images seront copiées\n",
    "output_dir = \"/Users/zakariaeanouk/Downloads/archive (1)/Test/images\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Créer le dossier s'il n'existe pas\n",
    "\n",
    "# Lire les chemins des images depuis train.txt\n",
    "with open(train_txt_path, \"r\") as file:\n",
    "    image_paths = file.readlines()\n",
    "\n",
    "# Supprimer les espaces ou caractères inutiles\n",
    "image_paths = [path.strip() for path in image_paths]\n",
    "\n",
    "# Copier les images dans le dossier de sortie\n",
    "for image_path in image_paths:\n",
    "    if os.path.exists(image_path):  # Vérifie que l'image existe\n",
    "        shutil.copy(image_path, output_dir)\n",
    "    else:\n",
    "        print(f\"Image non trouvée : {image_path}\")\n",
    "\n",
    "print(\"Les images ont été copiées dans le dossier 'test/images'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4def6c8-b1ba-4d15-9ddc-3b7f84c7f92c",
   "metadata": {},
   "source": [
    "### Déplacer les labels de train dans un dossier Train/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e23d8a-2f46-4db9-b5ce-95db21af4ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Dossiers\n",
    "images_dir = \"/Users/zakariaeanouk/Downloads/archive (1)/Train/images\"\n",
    "labels_src_dir = \"/Users/zakariaeanouk/Downloads/archive (1)/ts/ts\"\n",
    "labels_dest_dir = \"/Users/zakariaeanouk/Downloads/archive (1)/Train/labels\"\n",
    "\n",
    "# Créer le dossier de destination des labels s'il n'existe pas\n",
    "os.makedirs(labels_dest_dir, exist_ok=True)\n",
    "\n",
    "# Parcourir toutes les images du dossier d'images\n",
    "for image_file in os.listdir(images_dir):\n",
    "    if image_file.endswith(\".jpg\"):  # Vérifiez l'extension des images\n",
    "        # Remplacer l'extension de l'image par .txt pour trouver le label correspondant\n",
    "        label_file = image_file.replace(\".jpg\", \".txt\")\n",
    "        src_label_path = os.path.join(labels_src_dir, label_file)\n",
    "        dest_label_path = os.path.join(labels_dest_dir, label_file)\n",
    "\n",
    "        # Vérifiez si le fichier de label existe\n",
    "        if os.path.exists(src_label_path):\n",
    "            shutil.copy(src_label_path, dest_label_path)  # Copier le fichier label\n",
    "        else:\n",
    "            print(f\"Label non trouvé pour l'image : {image_file}\")\n",
    "\n",
    "print(\"Tous les labels ont été copiés dans le dossier 'Train/labels'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca680a44-2246-4e87-b60a-155586c27d0f",
   "metadata": {},
   "source": [
    "### Déplacer les labels de test dans un dossier Test/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1641be08-68db-4fee-8971-3cb4a3a7fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Dossiers\n",
    "images_dir = \"/Users/zakariaeanouk/Downloads/archive (1)/Test/images\"\n",
    "labels_src_dir = \"/Users/zakariaeanouk/Downloads/archive (1)/ts/ts\"\n",
    "labels_dest_dir = \"/Users/zakariaeanouk/Downloads/archive (1)/Test/labels\"\n",
    "\n",
    "# Créer le dossier de destination des labels s'il n'existe pas\n",
    "os.makedirs(labels_dest_dir, exist_ok=True)\n",
    "\n",
    "# Parcourir toutes les images du dossier d'images\n",
    "for image_file in os.listdir(images_dir):\n",
    "    if image_file.endswith(\".jpg\"):  # Vérifiez l'extension des images\n",
    "        # Remplacer l'extension de l'image par .txt pour trouver le label correspondant\n",
    "        label_file = image_file.replace(\".jpg\", \".txt\")\n",
    "        src_label_path = os.path.join(labels_src_dir, label_file)\n",
    "        dest_label_path = os.path.join(labels_dest_dir, label_file)\n",
    "\n",
    "        # Vérifiez si le fichier de label existe\n",
    "        if os.path.exists(src_label_path):\n",
    "            shutil.copy(src_label_path, dest_label_path)  # Copier le fichier label\n",
    "        else:\n",
    "            print(f\"Label non trouvé pour l'image : {image_file}\")\n",
    "\n",
    "print(\"Tous les labels ont été copiés dans le dossier 'Test/labels'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02261ca-3eaa-4c9a-b610-d52356df2d55",
   "metadata": {},
   "source": [
    "### Diviser le dossier Train en New_Train et Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52b5a04-9df8-4f85-ae43-7f2b02e4cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Chemins vers les dossiers d'entrée et de sortie\n",
    "images_dir = \"//Users/zakariaeanouk/Downloads/archive (1)/Train/images\"\n",
    "labels_dir = \"/Users/zakariaeanouk/Downloads/archive (1)/Train/labels\"\n",
    "output_dir = \"/Users/zakariaeanouk/Downloads/archive (1)/\"\n",
    "\n",
    "# Dossiers de sortie pour le nouveau Train et Validation\n",
    "new_train_images_dir = os.path.join(output_dir, \"New_Train/images\")\n",
    "new_train_labels_dir = os.path.join(output_dir, \"New_Train/labels\")\n",
    "val_images_dir = os.path.join(output_dir, \"New_Train\")\n",
    "val_labels_dir = os.path.join(output_dir, \"Validation/labels\")\n",
    "\n",
    "# Créer les dossiers pour Train et Validation\n",
    "os.makedirs(new_train_images_dir, exist_ok=True)\n",
    "os.makedirs(new_train_labels_dir, exist_ok=True)\n",
    "os.makedirs(val_images_dir, exist_ok=True)\n",
    "os.makedirs(val_labels_dir, exist_ok=True)\n",
    "\n",
    "# Liste de toutes les images et leurs labels correspondants\n",
    "all_images = [f for f in os.listdir(images_dir) if f.endswith(\".jpg\")]\n",
    "all_labels = [f.replace(\".jpg\", \".txt\") for f in all_images]\n",
    "\n",
    "# Diviser les données : 80% pour Train et 20% pour Validation\n",
    "train_images, val_images = train_test_split(all_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Copier les fichiers dans les dossiers correspondants\n",
    "for image in train_images:\n",
    "    shutil.copy(os.path.join(images_dir, image), os.path.join(new_train_images_dir, image))\n",
    "    shutil.copy(os.path.join(labels_dir, image.replace(\".jpg\", \".txt\")), os.path.join(new_train_labels_dir, image.replace(\".jpg\", \".txt\")))\n",
    "\n",
    "for image in val_images:\n",
    "    shutil.copy(os.path.join(images_dir, image), os.path.join(val_images_dir, image))\n",
    "    shutil.copy(os.path.join(labels_dir, image.replace(\".jpg\", \".txt\")), os.path.join(val_labels_dir, image.replace(\".jpg\", \".txt\")))\n",
    "\n",
    "print(\"Le dataset a été divisé en Train et Validation avec succès.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec30b0-cbe9-4ca6-b80e-865a76f32356",
   "metadata": {},
   "source": [
    "### changer les classes dans labels en une seule classe 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06367837-cb04-4039-a296-06a8ebae5e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Chemin vers les fichiers de labels\n",
    "labels_dir = \"/Users/zakariaeanouk/Downloads/archive (1)/Train/labels\"\n",
    "\n",
    "# Parcourir tous les fichiers de labels\n",
    "for label_file in os.listdir(labels_dir):\n",
    "    if label_file.endswith(\".txt\"):  # Vérifie que c'est un fichier de labels\n",
    "        file_path = os.path.join(labels_dir, label_file)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # Modifier chaque ligne pour mettre la classe à 0\n",
    "        new_lines = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            parts[0] = \"0\"  # Remplace le class_id par 0\n",
    "            new_lines.append(\" \".join(parts))\n",
    "        \n",
    "        # Écrire les modifications dans le fichier\n",
    "        with open(file_path, \"w\") as file:\n",
    "            file.write(\"\\n\".join(new_lines))\n",
    "\n",
    "print(\"Conversion des classes terminée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db35a6c-3a62-4a86-8ba2-c895f21f2b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Chemin vers les fichiers de labels\n",
    "labels_dir = \"/Users/zakariaeanouk/Downloads/archive (1)/Test/labels\"\n",
    "\n",
    "# Parcourir tous les fichiers de labels\n",
    "for label_file in os.listdir(labels_dir):\n",
    "    if label_file.endswith(\".txt\"):  # Vérifie que c'est un fichier de labels\n",
    "        file_path = os.path.join(labels_dir, label_file)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # Modifier chaque ligne pour mettre la classe à 0\n",
    "        new_lines = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            parts[0] = \"0\"  # Remplace le class_id par 0\n",
    "            new_lines.append(\" \".join(parts))\n",
    "        \n",
    "        # Écrire les modifications dans le fichier\n",
    "        with open(file_path, \"w\") as file:\n",
    "            file.write(\"\\n\".join(new_lines))\n",
    "\n",
    "print(\"Conversion des classes terminée.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5298cfa-5066-4994-a390-4837a3a1ac14",
   "metadata": {},
   "source": [
    "## Entrainement du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffcb0e5-200b-431a-bd70-bdf9ef907466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Charger les poids du dernier entraînement\n",
    "model = YOLO(\"yolov8n.pt\")  # Chemin des poids précédents\n",
    "# Entraînement avec augmentation\n",
    "\n",
    "model.train(\n",
    "    data=\"/kaggle/input/positionnement/ps/data.yaml\", \n",
    "    epochs=50, \n",
    "    imgsz=640, \n",
    "    batch=16, \n",
    "    augment=True,  # Active les augmentations par défaut\n",
    "    mosaic=True,   # Active les mosaïques (combinaison de plusieurs images dans une seule)\n",
    "    hsv_h=0.015,   # Variation de la teinte\n",
    "    hsv_s=0.7,     # Variation de la saturation\n",
    "    hsv_v=0.4,     # Variation de la luminosité\n",
    "    save=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afe6072-8c44-4909-9655-d426885da632",
   "metadata": {},
   "source": [
    "## Tester le modele et afficher les metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb4fc1-599e-465b-8d58-2298a0f2b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Charger le modèle\n",
    "model = YOLO(\"/kaggle/working/runs/detect/train/weights/best.pt\")\n",
    "\n",
    "# Évaluer les performances sur le dataset de test\n",
    "metrics = model.val(data=\"/kaggle/input/positionnement/ps/data.yaml\", split=\"test\")\n",
    "\n",
    "# Afficher les résultats\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b04160-695b-490c-9f11-38b1c02724c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Classification Model\n",
    "## Préparation du dataset\n",
    "### Création des labels pour les images de Train et Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04caf2d2-9c06-41f3-b2f5-4a94b15d6285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Chemins vers les fichiers\n",
    "train_csv = \"GTSRB/Train.csv\"\n",
    "train_images_dir = \"GTSRB/Train\"\n",
    "\n",
    "# Charger les annotations CSV\n",
    "annotations = pd.read_csv(train_csv)\n",
    "\n",
    "# Fonction pour convertir et créer les fichiers .txt\n",
    "def convert_to_yolo(annotations, images_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for _, row in annotations.iterrows():\n",
    "        image_width, image_height = row['Width'], row['Height']\n",
    "        x_min, y_min, x_max, y_max = row['Roi.X1'], row['Roi.Y1'], row['Roi.X2'], row['Roi.Y2']\n",
    "        class_id = row['ClassId']\n",
    "        \n",
    "        # Calcul des coordonnées normalisées\n",
    "        x_center = (x_min + x_max) / 2 / image_width\n",
    "        y_center = (y_min + y_max) / 2 / image_height\n",
    "        width = (x_max - x_min) / image_width\n",
    "        height = (y_max - y_min) / image_height\n",
    "        \n",
    "        # Créer un fichier .txt pour chaque image\n",
    "        image_path = row['Path']\n",
    "        filename = os.path.splitext(os.path.basename(image_path))[0] + \".txt\"\n",
    "        with open(os.path.join(output_dir, filename), 'w') as f:\n",
    "            f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "# Convertir les annotations d'entraînement\n",
    "convert_to_yolo(annotations, train_images_dir, \"GTSRB/train/labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf4ba87-7e1f-43b7-a190-a7e9f6d91756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Chemins vers les fichiers\n",
    "train_csv = \"GTSRB/Test.csv\"\n",
    "train_images_dir = \"GTSRB/Test\"\n",
    "\n",
    "# Charger les annotations CSV\n",
    "annotations = pd.read_csv(train_csv)\n",
    "\n",
    "# Fonction pour convertir et créer les fichiers .txt\n",
    "def convert_to_yolo(annotations, images_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for _, row in annotations.iterrows():\n",
    "        image_width, image_height = row['Width'], row['Height']\n",
    "        x_min, y_min, x_max, y_max = row['Roi.X1'], row['Roi.Y1'], row['Roi.X2'], row['Roi.Y2']\n",
    "        class_id = row['ClassId']\n",
    "        \n",
    "        # Calcul des coordonnées normalisées\n",
    "        x_center = (x_min + x_max) / 2 / image_width\n",
    "        y_center = (y_min + y_max) / 2 / image_height\n",
    "        width = (x_max - x_min) / image_width\n",
    "        height = (y_max - y_min) / image_height\n",
    "        \n",
    "        # Créer un fichier .txt pour chaque image\n",
    "        image_path = row['Path']\n",
    "        filename = os.path.splitext(os.path.basename(image_path))[0] + \".txt\"\n",
    "        with open(os.path.join(output_dir, filename), 'w') as f:\n",
    "            f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "# Convertir les annotations d'entraînement\n",
    "convert_to_yolo(annotations, train_images_dir, \"GTSRB/Test/labels\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a23afa-e34e-4c04-9f38-aa495767b925",
   "metadata": {},
   "source": [
    "### Regrouper les images de train dans un dossier GTSRB/Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf99da0-430d-48e6-b49f-479bd7092025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Dossiers source\n",
    "datasets = \"Train\"\n",
    "\n",
    "    # Créer le dossier images si nécessaire\n",
    "    images_dir = os.path.join(\"GTSRB\", dataset, \"images\")\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    \n",
    "    # Parcourir les sous-dossiers correspondant aux classes\n",
    "    class_dirs = [str(i) for i in range(43)]  # Classes de 0 à 42\n",
    "    for class_dir in class_dirs:\n",
    "        class_path = os.path.join(\"GTSRB\", dataset, class_dir)\n",
    "        if os.path.exists(class_path):  # Vérifier que le sous-dossier existe\n",
    "            # Déplacer toutes les images de ce sous-dossier\n",
    "            for file in os.listdir(class_path):\n",
    "                if file.endswith(\".png\"):  # Vérifie les fichiers image\n",
    "                    shutil.move(\n",
    "                        os.path.join(class_path, file),\n",
    "                        os.path.join(images_dir, file)\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107fc9ec-7e74-4d9a-9b9c-0cf261577c9e",
   "metadata": {},
   "source": [
    "### Regrouper les images de test dans un dossier GTSRB/Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0847222a-a8c6-416d-877f-2dd6cf0a18db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Dossiers source\n",
    "datasets = \"Test\"\n",
    "\n",
    "    # Créer le dossier images si nécessaire\n",
    "    images_dir = os.path.join(\"GTSRB\", dataset, \"images\")\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    \n",
    "    # Déplacer toutes les images dans le dossier images/\n",
    "    for file in os.listdir(os.path.join(\"GTSRB\", dataset)):\n",
    "        if file.endswith(\".png\"):  # Vérifie les fichiers image\n",
    "            shutil.move(\n",
    "                os.path.join(\"GTSRB\", dataset, file),\n",
    "                os.path.join(images_dir, file)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09112144-04d0-4c85-8a7c-0b3d233adf1d",
   "metadata": {},
   "source": [
    "### Deviser le dossier Train en 80% pour New_Train et 20% pour Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53458411-7d64-4941-8bb1-3060e147d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Chemins vers les dossiers d'entrée et de sortie\n",
    "images_dir = \"/Users/zakariaeanouk/Desktop/projet ML/GTSRB/Train/images\"\n",
    "labels_dir = \"/Users/zakariaeanouk/Desktop/projet ML/GTSRB/Train/labels\"\n",
    "output_dir = \"/Users/zakariaeanouk/Desktop/projet ML/GTSRB\"\n",
    "\n",
    "# Dossiers de sortie pour le nouveau Train et Validation\n",
    "new_train_images_dir = os.path.join(output_dir, \"New_Train/images\")\n",
    "new_train_labels_dir = os.path.join(output_dir, \"New_Train/labels\")\n",
    "val_images_dir = os.path.join(output_dir, \"Validation/images\")\n",
    "val_labels_dir = os.path.join(output_dir, \"Validation/labels\")\n",
    "\n",
    "# Créer les dossiers pour Train et Validation\n",
    "os.makedirs(new_train_images_dir, exist_ok=True)\n",
    "os.makedirs(new_train_labels_dir, exist_ok=True)\n",
    "os.makedirs(val_images_dir, exist_ok=True)\n",
    "os.makedirs(val_labels_dir, exist_ok=True)\n",
    "\n",
    "# Liste de toutes les images et leurs labels correspondants\n",
    "all_images = [f for f in os.listdir(images_dir) if f.endswith(\".png\")]\n",
    "all_labels = [f.replace(\".png\", \".txt\") for f in all_images]\n",
    "\n",
    "# Diviser les données : 80% pour Train et 20% pour Validation\n",
    "train_images, val_images = train_test_split(all_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Copier les fichiers dans les dossiers correspondants\n",
    "for image in train_images:\n",
    "    shutil.copy(os.path.join(images_dir, image), os.path.join(new_train_images_dir, image))\n",
    "    shutil.copy(os.path.join(labels_dir, image.replace(\".png\", \".txt\")), os.path.join(new_train_labels_dir, image.replace(\".png\", \".txt\")))\n",
    "\n",
    "for image in val_images:\n",
    "    shutil.copy(os.path.join(images_dir, image), os.path.join(val_images_dir, image))\n",
    "    shutil.copy(os.path.join(labels_dir, image.replace(\".png\", \".txt\")), os.path.join(val_labels_dir, image.replace(\".png\", \".txt\")))\n",
    "\n",
    "print(\"Le dataset a été divisé en Train et Validation avec succès.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb4489-d79e-480e-9bec-969236978c08",
   "metadata": {},
   "source": [
    "## Entrainer le modele de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2691f0-7892-4325-8272-2cbaee40df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Charger les poids du dernier entraînement\n",
    "model = YOLO(\"yolov8n.pt\")  # Chemin des poids précédents\n",
    "# Entraînement avec augmentation\n",
    "\n",
    "model.train(\n",
    "    data=\"/kaggle/input/projet/data.yaml\", \n",
    "    epochs=50, \n",
    "    imgsz=640, \n",
    "    batch=16, \n",
    "    augment=True,  # Active les augmentations par défaut\n",
    "    mosaic=True,   # Active les mosaïques (combinaison de plusieurs images dans une seule)\n",
    "    hsv_h=0.015,   # Variation de la teinte\n",
    "    hsv_s=0.7,     # Variation de la saturation\n",
    "    hsv_v=0.4,     # Variation de la luminosité\n",
    "    save=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c499cd-2355-49da-bc28-c3d8aaf13599",
   "metadata": {},
   "source": [
    "## Tester le modele sur les données du Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2d5e7c-01fd-403e-866a-285a4a1a1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Charger le modèle\n",
    "model = YOLO(\"/kaggle/input/modele/best.pt\")\n",
    "\n",
    "# Évaluer les performances sur le dataset de test\n",
    "metrics = model.val(data=\"/kaggle/working/data.yaml\", split=\"test\")\n",
    "\n",
    "# Afficher les résultats\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f395fce-f642-4bed-8034-ac0ab968b65e",
   "metadata": {},
   "source": [
    "# Combinaison des deux modeles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b5fdbf-d4c3-4535-bf23-22a555851a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO  # Assurez-vous d'importer YOLO si ce n'est pas déjà fait\n",
    "\n",
    "# Charger les modèles\n",
    "detection_model = YOLO('/Users/zakariaeanouk/Desktop/projet ML/detection/best.pt')\n",
    "classification_model = YOLO('/Users/zakariaeanouk/Desktop/projet ML/best.pt')\n",
    "\n",
    "# Charger l'image (utilisation de PIL)\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')  # Charger en mode RGB\n",
    "    return np.array(image)\n",
    "\n",
    "image = load_image('/Users/zakariaeanouk/Downloads/WhatsApp Image 2024-12-05 at 17.54.43.jpeg')\n",
    "\n",
    "# Étape 1 : Détection\n",
    "detections = detection_model.predict(image, save=True,imgsz=1024)  # Détection des bounding boxes\n",
    "print(detections[0])\n",
    "\n",
    "# Étape 2 : Classification\n",
    "if detections:\n",
    "    result = detections[0]  # Access the first result if there are multiple\n",
    "    boxes = result.boxes.xyxy  # Coordinates of the bounding boxes in [x_min, y_min, x_max, y_max]\n",
    "    boxes = boxes.cpu().numpy()  # Convert to numpy array (if you're using PyTorch)\n",
    "    print(\"Bounding boxes:\", boxes)\n",
    "else:\n",
    "    print(\"No detections found.\")\n",
    "\n",
    "# Traitement de chaque panneau détecté\n",
    "for box in boxes:\n",
    "    x1, y1, x2, y2 = map(int, box[:4])  # Convertir les coordonnées en entiers\n",
    "    roi = image[y1:y2, x1:x2]  # Extraire la région d'intérêt (ROI)\n",
    "    \n",
    "    # Redimensionner la ROI à la taille attendue par le modèle de classification (640, 640)\n",
    "    roi_resized = cv2.resize(roi, (640, 640))  # Resize to (640, 640) or any size divisible by 32\n",
    "    \n",
    "    # Conversion de la ROI en tensor\n",
    "    roi_tensor = torch.tensor(roi_resized).permute(2, 0, 1).unsqueeze(0).float()  # Convert to tensor\n",
    "\n",
    "    # Si les valeurs des pixels sont dans la plage 0-255, normalisez-les entre 0 et 1\n",
    "    roi_tensor = roi_tensor / 255.0  # Normalisation\n",
    "\n",
    "    # Prédiction avec le modèle de classification\n",
    "    class_label = classification_model.predict(roi_tensor,save=True)  # Prediction with the resized ROI\n",
    "    print(f\"Panneau détecté : {class_label} à la boîte {box}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d20ad28-7b4f-46c9-ae06-934c7881ec24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
